import ast
import csv

# æ‰‹åŠ¨å®šä¹‰æ¯ä¸ª cluster çš„æ ·æœ¬æ•°é‡
SAMPLE_COUNTS = {
    "0": 51,
    "2": 4,
    "3": 251,
    "4": 76,
    "5": 6,
    "6": 10,
}

# è¯»å– txt æ–‡ä»¶å†…å®¹
with open("summary_train.txt", "r") as f:
    content = f.read()

# åˆ†å‰²ä¸ºæ¯ä¸ª cluster çš„å—
blocks = content.split("cluster ")

metrics = {}  # { cluster_id: {metric_name: last_value} }

for block in blocks[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå—
    lines = block.strip().splitlines()
    cluster_id = lines[0].strip(":")  # å– ID å­—ç¬¦ä¸²
    cluster_metrics = {}
    for line in lines:
        if ":" in line and "[" in line:
            name, values_str = line.strip().split(": ", 1)
            values = ast.literal_eval(values_str)
            cluster_metrics[name.strip()] = values[-1]  # å–æœ€åä¸€è½®å€¼
    metrics[cluster_id] = cluster_metrics
    print(f"Per-Cluster Metrics (last round) - cluster {cluster_id}: {metrics[cluster_id]}")

# æ±‡æ€»æŒ‡æ ‡
total_samples = sum(SAMPLE_COUNTS.values())
weighted_metrics = {
    "MSE": 0,
    "RMSE": 0,
    "MAE": 0,
    "NRMSE": 0,
    "SSE": 0,
    "SST": 0,
}

# åŠ æƒç´¯è®¡
for cid, metric in metrics.items():
    count = SAMPLE_COUNTS.get(cid, 0)
    for k in weighted_metrics:
        if k in ["SSE", "SST"]:
            weighted_metrics[k] += metric[k]  # ç´¯åŠ 
        else:
            weighted_metrics[k] += metric[k] * count / total_samples  # æ ·æœ¬åŠ æƒå¹³å‡

# è¾“å‡ºåŠ æƒå¹³å‡ç»“æœ
print("\nğŸ“Š Final Weighted Global Metrics (last round):")
for k, v in weighted_metrics.items():
    print(f"{k}: {v:.6f}")

# æ·»åŠ æ ‡å‡† RÂ² è®¡ç®—ï¼ˆåŸºäºæ€» SSE / SSTï¼‰
global_r2 = 1 - (weighted_metrics["SSE"] / weighted_metrics["SST"])
print(f"\n Global R^2 (based on SSE/SST): {global_r2:.6f}")

