{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1965fde6",
   "metadata": {},
   "source": [
    "### In this notebook we perform Centralized learning, almost like 02.Individual_Training. \n",
    "\n",
    "In centralized learning there is an entity that has access to data from all base stations.\n",
    "Here, there is no option to filter out any base station.\n",
    "In this setting we also measure the energy consumption using the Carbontracker tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11879af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "parent = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f6cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d264d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.data_utils import read_data, generate_time_lags, time_to_feature, handle_nans, to_Xy, \\\n",
    "    to_torch_dataset, to_timeseries_rep, assign_statistics, \\\n",
    "    to_train_val, scale_features, get_data_by_area, remove_identifiers, get_exogenous_data_by_area, handle_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48559200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.train_utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c5e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.models.mlp import MLP\n",
    "from ml.models.rnn import RNN\n",
    "from ml.models.lstm import LSTM\n",
    "from ml.models.gru import GRU\n",
    "from ml.models.cnn import CNN\n",
    "from ml.models.rnn_autoencoder import DualAttentionAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e60d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path='../dataset/cluster_split/cluster_0.csv', # dataset\n",
    "    data_path_test=None , # test dataset\n",
    "    test_size=0.2, # validation size\n",
    "    targets=['power_output'], # the target columns\n",
    "    num_lags= 24, # the number of past observations to feed as input\n",
    "\n",
    "    \n",
    "    filter_bs=None, # whether to use a single bs for training. It will be changed dynamically\n",
    "    identifier='GSRN', # the column name that identifies a bs\n",
    "\n",
    "    nan_constant=0, # the constant to transform nan values\n",
    "    x_scaler='minmax', # x_scaler\n",
    "    y_scaler='minmax', # y_scaler\n",
    "    outlier_detection=None, # whether to perform flooring and capping\n",
    "\n",
    "    \n",
    "    criterion='mse', # optimization criterion, mse or l1\n",
    "    epochs=150, # the number of maximum epochs\n",
    "    lr=0.001, # learning rate\n",
    "    optimizer='adam', # the optimizer, it can be sgd or adam\n",
    "    batch_size=128, # the batch size to use\n",
    "    early_stopping=True, # whether to use early stopping\n",
    "    patience=50, # patience value for the early stopping parameter (if specified)\n",
    "    max_grad_norm=0.0, # whether to clip grad norm\n",
    "    reg1=0.0, # l1 regularization\n",
    "    reg2=0.0, # l2 regularization\n",
    "    \n",
    "    plot_history=True, # plot loss history\n",
    "\n",
    "    cuda=True, # whether to use gpu\n",
    "    \n",
    "    seed=0, # reproducibility\n",
    "\n",
    "    assign_stats=None, # whether to use statistics as exogenous data, [\"mean\", \"median\", \"std\", \"variance\", \"kurtosis\", \"skew\"]\n",
    "    use_time_features=False # whether to use datetime features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0660fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script arguments: Namespace(data_path='../dataset/cluster_split/cluster_0.csv', data_path_test=None, test_size=0.2, targets=['power_output'], num_lags=24, filter_bs=None, identifier='GSRN', nan_constant=0, x_scaler='minmax', y_scaler='minmax', outlier_detection=None, criterion='mse', epochs=150, lr=0.001, optimizer='adam', batch_size=128, early_stopping=True, patience=50, max_grad_norm=0.0, reg1=0.0, reg2=0.0, plot_history=True, cuda=True, seed=0, assign_stats=None, use_time_features=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Script arguments: {args}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e574ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the device currently used is mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"the device currently used is\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b20d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection specification\n",
    "if args.outlier_detection is not None:\n",
    "    outlier_columns = ['rb_down', 'rb_up', 'down', 'up']\n",
    "    outlier_kwargs = {\"ElBorn\": (10, 90), \"LesCorts\": (10, 90), \"PobleSec\": (5, 95)}\n",
    "    args.outlier_columns = outlier_columns\n",
    "    args.outlier_kwargs = outlier_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d661a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all():\n",
    "    # ensure reproducibility\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b0bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd59b3",
   "metadata": {},
   "source": [
    "### By setting filter_bs to None, the preprocessing pipeline returns data from all three base stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660ef8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_to_skip = [\n",
    "    \"570714700000004469\",\n",
    "    \"570714700000004568\",\n",
    "    \"570714700000004704\",\n",
    "    \"570714700000004964\",\n",
    "    \"570714700000005060\",\n",
    "    \"570714700000005619\",\n",
    "    \"570714700000005626\",\n",
    "    \"570714700000006029\",\n",
    "    \"570714700000006296\",\n",
    "    \"570714700000006890\",\n",
    "    \"570714700000006982\",\n",
    "    \"570714700000007194\",\n",
    "    \"570714700000008252\",\n",
    "    \"570714700000008627\",\n",
    "    \"570715000000083464\",\n",
    "]\n",
    "\n",
    "# Remove skipped clients (for DataFrame structure)\n",
    "def filter_df_by_gsrn(df, clients_to_skip):\n",
    "    if df is None:\n",
    "        return None\n",
    "    return df[~df[\"GSRN\"].isin(clients_to_skip)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf0480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessing(filter_bs=None):\n",
    "    \"\"\"Preprocess a given .csv\"\"\"\n",
    "    # read data\n",
    "    df = read_data(args.data_path, filter_data=filter_bs)\n",
    "\n",
    "    # filter out clients to skip in cluster 4\n",
    "    df = filter_df_by_gsrn(df, clients_to_skip)\n",
    "    print(f\"Filtered out {len(clients_to_skip)} clients. Remaining rows: {len(df)}\")\n",
    "    \n",
    "    # handle nans\n",
    "    df = handle_nans(train_data=df, constant=args.nan_constant,\n",
    "                     identifier=args.identifier)\n",
    "    # split to train/validation\n",
    "    train_data, val_data = to_train_val(df)\n",
    "    \n",
    "    # handle outliers (if specified)\n",
    "    if args.outlier_detection is not None:\n",
    "        train_data = handle_outliers(df=train_data, columns=args.outlier_columns,\n",
    "                                     identifier=args.identifier, kwargs=args.outlier_kwargs)\n",
    "    \n",
    "    # get X and y\n",
    "    X_train, X_val, y_train, y_val = to_Xy(train_data=train_data, val_data=val_data,\n",
    "                                          targets=args.targets)\n",
    "    \n",
    "    # drop cluster columns from X\n",
    "    if \"cluster\" in X_train.columns:\n",
    "        X_train = X_train.drop(columns=[\"cluster\"])\n",
    "    if \"cluster\" in X_val.columns:\n",
    "        X_val = X_val.drop(columns=[\"cluster\"])\n",
    "    \n",
    "    # scale X\n",
    "    X_train, X_val, x_scaler = scale_features(train_data=X_train, val_data=X_val,\n",
    "                                             scaler=args.x_scaler, identifier=args.identifier)\n",
    "    # scale y\n",
    "    y_train, y_val, y_scaler = scale_features(train_data=y_train, val_data=y_val,\n",
    "                                             scaler=args.y_scaler, identifier=args.identifier)\n",
    "    \n",
    "    # generate time lags\n",
    "    X_train = generate_time_lags(X_train, args.num_lags)\n",
    "    X_val = generate_time_lags(X_val, args.num_lags)\n",
    "    y_train = generate_time_lags(y_train, args.num_lags, is_y=True)\n",
    "    y_val = generate_time_lags(y_val, args.num_lags, is_y=True)\n",
    "    \n",
    "    # get datetime features as exogenous data\n",
    "    date_time_df_train = time_to_feature(\n",
    "        X_train, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    date_time_df_val = time_to_feature(\n",
    "        X_val, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    \n",
    "    # get statistics as exogenous data\n",
    "    stats_df_train = assign_statistics(X_train, args.assign_stats, args.num_lags,\n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    stats_df_val = assign_statistics(X_val, args.assign_stats, args.num_lags, \n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    \n",
    "    # concat the exogenous features (if any) to a single dataframe\n",
    "    if date_time_df_train is not None or stats_df_train is not None:\n",
    "        exogenous_data_train = pd.concat([date_time_df_train, stats_df_train], axis=1)\n",
    "        # remove duplicate columns (if any)\n",
    "        exogenous_data_train = exogenous_data_train.loc[:, ~exogenous_data_train.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_train) == len(X_train) == len(y_train)\n",
    "    else:\n",
    "        exogenous_data_train = None\n",
    "    if date_time_df_val is not None or stats_df_val is not None:\n",
    "        exogenous_data_val = pd.concat([date_time_df_val, stats_df_val], axis=1)\n",
    "        exogenous_data_val = exogenous_data_val.loc[:, ~exogenous_data_val.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_val) == len(X_val) == len(y_val)\n",
    "    else:\n",
    "        exogenous_data_val = None\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85eb3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libowen/Library/Python/3.10/lib/python/site-packages/sklearn/impute/_base.py:590: FutureWarning: Currently, when `keep_empty_feature=False` and `strategy=\"constant\"`, empty features are not dropped. This behaviour will change in version 1.8. Set `keep_empty_feature=True` to preserve this behaviour.\n",
      "  warnings.warn(\n",
      "INFO logger 2025-10-28 13:24:09,593 | data_utils.py:393 | Observations info in 570715000000128905\n",
      "INFO logger 2025-10-28 13:24:09,594 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,594 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,594 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,596 | data_utils.py:393 | Observations info in 570715000000088643\n",
      "INFO logger 2025-10-28 13:24:09,596 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,596 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,597 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,598 | data_utils.py:393 | Observations info in 570715000000088667\n",
      "INFO logger 2025-10-28 13:24:09,598 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,599 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,599 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,600 | data_utils.py:393 | Observations info in 570715000000125669\n",
      "INFO logger 2025-10-28 13:24:09,601 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,601 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,601 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,603 | data_utils.py:393 | Observations info in 570715000000125706\n",
      "INFO logger 2025-10-28 13:24:09,603 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,604 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,604 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,605 | data_utils.py:393 | Observations info in 570715000000125652\n",
      "INFO logger 2025-10-28 13:24:09,605 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,606 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,606 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,607 | data_utils.py:393 | Observations info in 570715000000125683\n",
      "INFO logger 2025-10-28 13:24:09,608 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,608 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,608 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,610 | data_utils.py:393 | Observations info in 571313161170169709\n",
      "INFO logger 2025-10-28 13:24:09,610 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,610 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,611 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,612 | data_utils.py:393 | Observations info in 571313161170169150\n",
      "INFO logger 2025-10-28 13:24:09,613 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,613 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,613 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,614 | data_utils.py:393 | Observations info in 571313161170169785\n",
      "INFO logger 2025-10-28 13:24:09,615 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,615 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,615 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,616 | data_utils.py:393 | Observations info in 570715000000125621\n",
      "INFO logger 2025-10-28 13:24:09,617 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,617 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,617 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,619 | data_utils.py:393 | Observations info in 570715000000125614\n",
      "INFO logger 2025-10-28 13:24:09,619 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,619 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,619 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,621 | data_utils.py:393 | Observations info in 571313174001641268\n",
      "INFO logger 2025-10-28 13:24:09,621 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,621 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,621 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,622 | data_utils.py:393 | Observations info in 570715000000125591\n",
      "INFO logger 2025-10-28 13:24:09,623 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,623 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,623 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,624 | data_utils.py:393 | Observations info in 571313174001641251\n",
      "INFO logger 2025-10-28 13:24:09,624 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,624 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,624 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,625 | data_utils.py:393 | Observations info in 570715000000125546\n",
      "INFO logger 2025-10-28 13:24:09,626 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,626 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,626 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,627 | data_utils.py:393 | Observations info in 571313174001641244\n",
      "INFO logger 2025-10-28 13:24:09,627 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,627 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,628 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,629 | data_utils.py:393 | Observations info in 571313174001641237\n",
      "INFO logger 2025-10-28 13:24:09,629 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,629 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,629 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,630 | data_utils.py:393 | Observations info in 571313174001641220\n",
      "INFO logger 2025-10-28 13:24:09,630 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,630 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,631 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,632 | data_utils.py:393 | Observations info in 570715000000084652\n",
      "INFO logger 2025-10-28 13:24:09,632 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,632 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,632 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,633 | data_utils.py:393 | Observations info in 571313174000780944\n",
      "INFO logger 2025-10-28 13:24:09,633 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,634 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,634 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,635 | data_utils.py:393 | Observations info in 570715000000084607\n",
      "INFO logger 2025-10-28 13:24:09,636 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,636 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,636 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,637 | data_utils.py:393 | Observations info in 571313174000780951\n",
      "INFO logger 2025-10-28 13:24:09,637 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,637 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,638 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,639 | data_utils.py:393 | Observations info in 571313174000602154\n",
      "INFO logger 2025-10-28 13:24:09,639 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,639 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,639 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,640 | data_utils.py:393 | Observations info in 571313174000602147\n",
      "INFO logger 2025-10-28 13:24:09,640 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,640 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,641 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,641 | data_utils.py:393 | Observations info in 571313174000602130\n",
      "INFO logger 2025-10-28 13:24:09,642 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,642 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,643 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,645 | data_utils.py:393 | Observations info in 571313174000602109\n",
      "INFO logger 2025-10-28 13:24:09,646 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,647 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,647 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,650 | data_utils.py:393 | Observations info in 571313174000602116\n",
      "INFO logger 2025-10-28 13:24:09,650 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,650 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,651 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,653 | data_utils.py:393 | Observations info in 571313174000602123\n",
      "INFO logger 2025-10-28 13:24:09,654 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,654 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,655 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,657 | data_utils.py:393 | Observations info in 571313174000839574\n",
      "INFO logger 2025-10-28 13:24:09,658 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,659 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,660 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,663 | data_utils.py:393 | Observations info in 571313174000839604\n",
      "INFO logger 2025-10-28 13:24:09,664 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,664 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,664 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,666 | data_utils.py:393 | Observations info in 571313174000839611\n",
      "INFO logger 2025-10-28 13:24:09,667 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,667 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,667 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,670 | data_utils.py:393 | Observations info in 571313174000828844\n",
      "INFO logger 2025-10-28 13:24:09,671 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,672 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,672 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,674 | data_utils.py:393 | Observations info in 570715000000088872\n",
      "INFO logger 2025-10-28 13:24:09,675 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,676 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,677 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,679 | data_utils.py:393 | Observations info in 570715000000088865\n",
      "INFO logger 2025-10-28 13:24:09,680 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,681 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,681 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,683 | data_utils.py:393 | Observations info in 570715000000088858\n",
      "INFO logger 2025-10-28 13:24:09,684 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,684 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,684 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,687 | data_utils.py:393 | Observations info in 570715000000088810\n",
      "INFO logger 2025-10-28 13:24:09,688 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,689 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,689 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,692 | data_utils.py:393 | Observations info in 571313174001657979\n",
      "INFO logger 2025-10-28 13:24:09,736 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,740 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,741 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,745 | data_utils.py:393 | Observations info in 571313174001657962\n",
      "INFO logger 2025-10-28 13:24:09,746 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,747 | data_utils.py:395 | \tNumber of samples for training: 7008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 15 clients. Remaining rows: 446760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2025-10-28 13:24:09,759 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,762 | data_utils.py:393 | Observations info in 571313174001657931\n",
      "INFO logger 2025-10-28 13:24:09,762 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,763 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,763 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,765 | data_utils.py:393 | Observations info in 571313174000832759\n",
      "INFO logger 2025-10-28 13:24:09,766 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,766 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,766 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,768 | data_utils.py:393 | Observations info in 571313174000832742\n",
      "INFO logger 2025-10-28 13:24:09,768 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,768 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,769 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,771 | data_utils.py:393 | Observations info in 571313174000832711\n",
      "INFO logger 2025-10-28 13:24:09,771 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,771 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,771 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,773 | data_utils.py:393 | Observations info in 570715000000161025\n",
      "INFO logger 2025-10-28 13:24:09,774 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,774 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,774 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,776 | data_utils.py:393 | Observations info in 570715000000161001\n",
      "INFO logger 2025-10-28 13:24:09,776 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,776 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,776 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,778 | data_utils.py:393 | Observations info in 570715000000161018\n",
      "INFO logger 2025-10-28 13:24:09,778 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,778 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,779 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,781 | data_utils.py:393 | Observations info in 570715000000161032\n",
      "INFO logger 2025-10-28 13:24:09,782 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,782 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,783 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,784 | data_utils.py:393 | Observations info in 570715000000161056\n",
      "INFO logger 2025-10-28 13:24:09,785 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,786 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,786 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,787 | data_utils.py:393 | Observations info in 570715000000161049\n",
      "INFO logger 2025-10-28 13:24:09,788 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,788 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,789 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,790 | data_utils.py:393 | Observations info in 570715000000089336\n",
      "INFO logger 2025-10-28 13:24:09,791 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,792 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,792 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,795 | data_utils.py:393 | Observations info in 570715000000088827\n",
      "INFO logger 2025-10-28 13:24:09,796 | data_utils.py:394 | \tTotal number of samples:  8760\n",
      "INFO logger 2025-10-28 13:24:09,796 | data_utils.py:395 | \tNumber of samples for training: 7008\n",
      "INFO logger 2025-10-28 13:24:09,797 | data_utils.py:396 | \tNumber of samples for validation:  1752\n",
      "INFO logger 2025-10-28 13:24:09,851 | data_utils.py:399 | Observations info using all data\n",
      "INFO logger 2025-10-28 13:24:09,852 | data_utils.py:400 | \tTotal number of samples:  446760\n",
      "INFO logger 2025-10-28 13:24:09,853 | data_utils.py:401 | \tNumber of samples for training: 357408\n",
      "INFO logger 2025-10-28 13:24:09,853 | data_utils.py:402 | \tNumber of samples for validation:  89352\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler = make_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e64887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capacity_kw_lag-24</th>\n",
       "      <th>power_output_lag-24</th>\n",
       "      <th>age_lag-24</th>\n",
       "      <th>wind_dir_cos_lag-24</th>\n",
       "      <th>wind_dir_sin_lag-24</th>\n",
       "      <th>hour_cos_lag-24</th>\n",
       "      <th>hour_sin_lag-24</th>\n",
       "      <th>temperature_c_lag-24</th>\n",
       "      <th>wind_speed_lag-24</th>\n",
       "      <th>Capacity_kw_lag-23</th>\n",
       "      <th>...</th>\n",
       "      <th>Capacity_kw_lag-1</th>\n",
       "      <th>power_output_lag-1</th>\n",
       "      <th>age_lag-1</th>\n",
       "      <th>wind_dir_cos_lag-1</th>\n",
       "      <th>wind_dir_sin_lag-1</th>\n",
       "      <th>hour_cos_lag-1</th>\n",
       "      <th>hour_sin_lag-1</th>\n",
       "      <th>temperature_c_lag-1</th>\n",
       "      <th>wind_speed_lag-1</th>\n",
       "      <th>GSRN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.37905</td>\n",
       "      <td>0.01485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.96985</td>\n",
       "      <td>0.32900</td>\n",
       "      <td>0.98295</td>\n",
       "      <td>0.37060</td>\n",
       "      <td>0.230137</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 01:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951725</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.37905</td>\n",
       "      <td>0.01485</td>\n",
       "      <td>0.98295</td>\n",
       "      <td>0.62940</td>\n",
       "      <td>0.331507</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.98065</td>\n",
       "      <td>0.36220</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 02:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951565</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.38750</td>\n",
       "      <td>0.01280</td>\n",
       "      <td>0.93300</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.326027</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.98905</td>\n",
       "      <td>0.39605</td>\n",
       "      <td>0.98295</td>\n",
       "      <td>0.62940</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 03:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.35380</td>\n",
       "      <td>0.02185</td>\n",
       "      <td>0.85355</td>\n",
       "      <td>0.85355</td>\n",
       "      <td>0.326027</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.99515</td>\n",
       "      <td>0.43040</td>\n",
       "      <td>0.93300</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.189041</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 04:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.33720</td>\n",
       "      <td>0.02725</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.93300</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.43905</td>\n",
       "      <td>0.85355</td>\n",
       "      <td>0.85355</td>\n",
       "      <td>0.180822</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Capacity_kw_lag-24  power_output_lag-24  age_lag-24  \\\n",
       "time                                                                       \n",
       "2019-01-02 00:00:00                 1.0             0.951698    0.666667   \n",
       "2019-01-02 01:00:00                 1.0             0.951725    0.666667   \n",
       "2019-01-02 02:00:00                 1.0             0.951565    0.666667   \n",
       "2019-01-02 03:00:00                 1.0             0.021217    0.666667   \n",
       "2019-01-02 04:00:00                 1.0             0.000000    0.666667   \n",
       "\n",
       "                     wind_dir_cos_lag-24  wind_dir_sin_lag-24  \\\n",
       "time                                                            \n",
       "2019-01-02 00:00:00              0.37905              0.01485   \n",
       "2019-01-02 01:00:00              0.37905              0.01485   \n",
       "2019-01-02 02:00:00              0.38750              0.01280   \n",
       "2019-01-02 03:00:00              0.35380              0.02185   \n",
       "2019-01-02 04:00:00              0.33720              0.02725   \n",
       "\n",
       "                     hour_cos_lag-24  hour_sin_lag-24  temperature_c_lag-24  \\\n",
       "time                                                                          \n",
       "2019-01-02 00:00:00          1.00000          0.50000              0.336986   \n",
       "2019-01-02 01:00:00          0.98295          0.62940              0.331507   \n",
       "2019-01-02 02:00:00          0.93300          0.75000              0.326027   \n",
       "2019-01-02 03:00:00          0.85355          0.85355              0.326027   \n",
       "2019-01-02 04:00:00          0.75000          0.93300              0.328767   \n",
       "\n",
       "                     wind_speed_lag-24  Capacity_kw_lag-23  ...  \\\n",
       "time                                                        ...   \n",
       "2019-01-02 00:00:00           0.500000                 1.0  ...   \n",
       "2019-01-02 01:00:00           0.575000                 1.0  ...   \n",
       "2019-01-02 02:00:00           0.620833                 1.0  ...   \n",
       "2019-01-02 03:00:00           0.666667                 1.0  ...   \n",
       "2019-01-02 04:00:00           0.695833                 1.0  ...   \n",
       "\n",
       "                     Capacity_kw_lag-1  power_output_lag-1  age_lag-1  \\\n",
       "time                                                                    \n",
       "2019-01-02 00:00:00                1.0            0.007541   0.666667   \n",
       "2019-01-02 01:00:00                1.0            0.000000   0.666667   \n",
       "2019-01-02 02:00:00                1.0            0.000000   0.666667   \n",
       "2019-01-02 03:00:00                1.0            0.000000   0.666667   \n",
       "2019-01-02 04:00:00                1.0            0.000000   0.666667   \n",
       "\n",
       "                     wind_dir_cos_lag-1  wind_dir_sin_lag-1  hour_cos_lag-1  \\\n",
       "time                                                                          \n",
       "2019-01-02 00:00:00             0.96985             0.32900         0.98295   \n",
       "2019-01-02 01:00:00             0.98065             0.36220         1.00000   \n",
       "2019-01-02 02:00:00             0.98905             0.39605         0.98295   \n",
       "2019-01-02 03:00:00             0.99515             0.43040         0.93300   \n",
       "2019-01-02 04:00:00             0.99625             0.43905         0.85355   \n",
       "\n",
       "                     hour_sin_lag-1  temperature_c_lag-1  wind_speed_lag-1  \\\n",
       "time                                                                         \n",
       "2019-01-02 00:00:00         0.37060             0.230137          0.808333   \n",
       "2019-01-02 01:00:00         0.50000             0.213699          0.787500   \n",
       "2019-01-02 02:00:00         0.62940             0.200000          0.754167   \n",
       "2019-01-02 03:00:00         0.75000             0.189041          0.737500   \n",
       "2019-01-02 04:00:00         0.85355             0.180822          0.695833   \n",
       "\n",
       "                                   GSRN  \n",
       "time                                     \n",
       "2019-01-02 00:00:00  570715000000128905  \n",
       "2019-01-02 01:00:00  570715000000128905  \n",
       "2019-01-02 02:00:00  570715000000128905  \n",
       "2019-01-02 03:00:00  570715000000128905  \n",
       "2019-01-02 04:00:00  570715000000128905  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591b150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_output</th>\n",
       "      <th>GSRN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>570715000000128905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     power_output                GSRN\n",
       "time                                                 \n",
       "2019-01-02 00:00:00           0.0  570715000000128905\n",
       "2019-01-02 01:00:00           0.0  570715000000128905\n",
       "2019-01-02 02:00:00           0.0  570715000000128905\n",
       "2019-01-02 03:00:00           0.0  570715000000128905\n",
       "2019-01-02 04:00:00           0.0  570715000000128905"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0fa465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MinMaxScaler(), MinMaxScaler())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55102f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler):\n",
    "    \"\"\"Make data ready to be fed into ml algorithms\"\"\"\n",
    "    # if there are more than one specified areas, get the data per area\n",
    "    if X_train[args.identifier].nunique() != 1:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = get_data_by_area(X_train, X_val,\n",
    "                                                                              y_train, y_val, \n",
    "                                                                              identifier=args.identifier)\n",
    "    else:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = None, None, None, None\n",
    "\n",
    "    # Get the exogenous data per area.\n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train, exogenous_data_val = get_exogenous_data_by_area(exogenous_data_train,\n",
    "                                                                              exogenous_data_val)\n",
    "    # transform to np\n",
    "    if area_X_train is not None:\n",
    "        for area in area_X_train:\n",
    "            tmp_X_train, tmp_y_train, tmp_X_val, tmp_y_val = remove_identifiers(\n",
    "                area_X_train[area], area_y_train[area], area_X_val[area], area_y_val[area])\n",
    "            tmp_X_train, tmp_y_train = tmp_X_train.to_numpy(), tmp_y_train.to_numpy()\n",
    "            tmp_X_val, tmp_y_val = tmp_X_val.to_numpy(), tmp_y_val.to_numpy()\n",
    "            area_X_train[area] = tmp_X_train\n",
    "            area_X_val[area] = tmp_X_val\n",
    "            area_y_train[area] = tmp_y_train\n",
    "            area_y_val[area] = tmp_y_val\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train[area] = exogenous_data_train[area].to_numpy()\n",
    "            exogenous_data_val[area] = exogenous_data_val[area].to_numpy()\n",
    "    \n",
    "    # remove identifiers from features, targets\n",
    "    X_train, y_train, X_val, y_val = remove_identifiers(X_train, y_train, X_val, y_val)\n",
    "    assert len(X_train.columns) == len(X_val.columns)\n",
    "    \n",
    "    num_features = len(X_train.columns) // args.num_lags\n",
    "    \n",
    "    # to timeseries representation\n",
    "    X_train = to_timeseries_rep(X_train.to_numpy(), num_lags=args.num_lags,\n",
    "                                            num_features=num_features)\n",
    "    X_val = to_timeseries_rep(X_val.to_numpy(), num_lags=args.num_lags,\n",
    "                                          num_features=num_features)\n",
    "    \n",
    "    if area_X_train is not None:\n",
    "        area_X_train = to_timeseries_rep(area_X_train, num_lags=args.num_lags,\n",
    "                                                     num_features=num_features)\n",
    "        area_X_val = to_timeseries_rep(area_X_val, num_lags=args.num_lags,\n",
    "                                                   num_features=num_features)\n",
    "    \n",
    "    # transform targets to numpy\n",
    "    y_train, y_val = y_train.to_numpy(), y_val.to_numpy()\n",
    "    \n",
    "    # centralized (all) learning specific\n",
    "    if not args.filter_bs and exogenous_data_train is not None:\n",
    "        exogenous_data_train_combined, exogenous_data_val_combined = [], []\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train_combined.extend(exogenous_data_train[area])\n",
    "            exogenous_data_val_combined.extend(exogenous_data_val[area])\n",
    "        exogenous_data_train_combined = np.stack(exogenous_data_train_combined)\n",
    "        exogenous_data_val_combined = np.stack(exogenous_data_val_combined)\n",
    "        exogenous_data_train[\"all\"] = exogenous_data_train_combined\n",
    "        exogenous_data_val[\"all\"] = exogenous_data_val_combined\n",
    "    return X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698aa32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce3616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val = make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scaler, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6592db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([570715000000128905, 570715000000088643, 570715000000088667, 570715000000125669, 570715000000125706, 570715000000125652, 570715000000125683, 571313161170169709, 571313161170169150, 571313161170169785, 570715000000125621, 570715000000125614, 571313174001641268, 570715000000125591, 571313174001641251, 570715000000125546, 571313174001641244, 571313174001641237, 571313174001641220, 570715000000084652, 571313174000780944, 570715000000084607, 571313174000780951, 571313174000602154, 571313174000602147, 571313174000602130, 571313174000602109, 571313174000602116, 571313174000602123, 571313174000839574, 571313174000839604, 571313174000839611, 571313174000828844, 570715000000088872, 570715000000088865, 570715000000088858, 570715000000088810, 571313174001657979, 571313174001657962, 571313174001657931, 571313174000832759, 571313174000832742, 571313174000832711, 570715000000161025, 570715000000161001, 570715000000161018, 570715000000161032, 570715000000161056, 570715000000161049, 570715000000089336, 570715000000088827])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d521ab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([570715000000128905, 570715000000088643, 570715000000088667, 570715000000125669, 570715000000125706, 570715000000125652, 570715000000125683, 571313161170169709, 571313161170169150, 571313161170169785, 570715000000125621, 570715000000125614, 571313174001641268, 570715000000125591, 571313174001641251, 570715000000125546, 571313174001641244, 571313174001641237, 571313174001641220, 570715000000084652, 571313174000780944, 570715000000084607, 571313174000780951, 571313174000602154, 571313174000602147, 571313174000602130, 571313174000602109, 571313174000602116, 571313174000602123, 571313174000839574, 571313174000839604, 571313174000839611, 571313174000828844, 570715000000088872, 570715000000088865, 570715000000088858, 570715000000088810, 571313174001657979, 571313174001657962, 571313174001657931, 571313174000832759, 571313174000832742, 571313174000832711, 570715000000161025, 570715000000161001, 570715000000161018, 570715000000161032, 570715000000161056, 570715000000161049, 570715000000089336, 570715000000088827])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_X_val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c90c8a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        ],\n",
       "         [0.95169818],\n",
       "         [0.66666669],\n",
       "         [0.37905002],\n",
       "         [0.01484999],\n",
       "         [1.        ],\n",
       "         [0.5       ],\n",
       "         [0.3369863 ],\n",
       "         [0.50000006]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95172477],\n",
       "         [0.66666669],\n",
       "         [0.37905002],\n",
       "         [0.01484999],\n",
       "         [0.98294997],\n",
       "         [0.62940001],\n",
       "         [0.33150685],\n",
       "         [0.57499999]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95156538],\n",
       "         [0.66666669],\n",
       "         [0.38749999],\n",
       "         [0.01280001],\n",
       "         [0.93299997],\n",
       "         [0.75      ],\n",
       "         [0.32602739],\n",
       "         [0.62083334]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.02121671],\n",
       "         [0.66666669],\n",
       "         [0.3538    ],\n",
       "         [0.02184999],\n",
       "         [0.85354996],\n",
       "         [0.85354996],\n",
       "         [0.32602739],\n",
       "         [0.66666669]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.33719999],\n",
       "         [0.02724999],\n",
       "         [0.75      ],\n",
       "         [0.93299997],\n",
       "         [0.32876712],\n",
       "         [0.69583333]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.39605001],\n",
       "         [0.01095   ],\n",
       "         [0.62940001],\n",
       "         [0.98294997],\n",
       "         [0.34246576],\n",
       "         [0.69166672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.6462    ],\n",
       "         [0.02184999],\n",
       "         [0.5       ],\n",
       "         [1.        ],\n",
       "         [0.37534246],\n",
       "         [0.71250004]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.04012321],\n",
       "         [0.66666669],\n",
       "         [0.63779998],\n",
       "         [0.01934999],\n",
       "         [0.37059999],\n",
       "         [0.98294997],\n",
       "         [0.33972603],\n",
       "         [0.67083341]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95047665],\n",
       "         [0.66666669],\n",
       "         [0.59539998],\n",
       "         [0.00920001],\n",
       "         [0.25      ],\n",
       "         [0.93299997],\n",
       "         [0.3068493 ],\n",
       "         [0.70416671]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95005184],\n",
       "         [0.66666669],\n",
       "         [0.60395002],\n",
       "         [0.01095   ],\n",
       "         [0.14645001],\n",
       "         [0.85354996],\n",
       "         [0.30958903],\n",
       "         [0.75416672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.63535941],\n",
       "         [0.66666669],\n",
       "         [0.65450001],\n",
       "         [0.02445   ],\n",
       "         [0.067     ],\n",
       "         [0.75      ],\n",
       "         [0.31506848],\n",
       "         [0.83750004]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.63530636],\n",
       "         [0.66666669],\n",
       "         [0.68729997],\n",
       "         [0.03639999],\n",
       "         [0.01705   ],\n",
       "         [0.62940001],\n",
       "         [0.30958903],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.40094003],\n",
       "         [0.66666669],\n",
       "         [0.67919999],\n",
       "         [0.0332    ],\n",
       "         [0.        ],\n",
       "         [0.5       ],\n",
       "         [0.30136985],\n",
       "         [0.85000002]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.68817556],\n",
       "         [0.66666669],\n",
       "         [0.68729997],\n",
       "         [0.03639999],\n",
       "         [0.01705   ],\n",
       "         [0.37059999],\n",
       "         [0.29315066],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95050323],\n",
       "         [0.66666669],\n",
       "         [0.70335001],\n",
       "         [0.04324999],\n",
       "         [0.067     ],\n",
       "         [0.25      ],\n",
       "         [0.28219178],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95066261],\n",
       "         [0.66666669],\n",
       "         [0.71130002],\n",
       "         [0.04685   ],\n",
       "         [0.14645001],\n",
       "         [0.14645001],\n",
       "         [0.27945206],\n",
       "         [0.81666672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95084846],\n",
       "         [0.66666669],\n",
       "         [0.727     ],\n",
       "         [0.05450001],\n",
       "         [0.25      ],\n",
       "         [0.067     ],\n",
       "         [0.27945206],\n",
       "         [0.77916664]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95106089],\n",
       "         [0.66666669],\n",
       "         [0.7723    ],\n",
       "         [0.08065   ],\n",
       "         [0.37059999],\n",
       "         [0.01705   ],\n",
       "         [0.27123287],\n",
       "         [0.68750006]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95095468],\n",
       "         [0.66666669],\n",
       "         [0.88855004],\n",
       "         [0.18535   ],\n",
       "         [0.5       ],\n",
       "         [0.        ],\n",
       "         [0.25205481],\n",
       "         [0.65833336]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95005184],\n",
       "         [0.66666669],\n",
       "         [0.96025002],\n",
       "         [0.30465001],\n",
       "         [0.62940001],\n",
       "         [0.01705   ],\n",
       "         [0.29863015],\n",
       "         [0.66250002]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95100772],\n",
       "         [0.66666669],\n",
       "         [0.96679997],\n",
       "         [0.32080001],\n",
       "         [0.75      ],\n",
       "         [0.067     ],\n",
       "         [0.28493151],\n",
       "         [0.74583334]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.03664463],\n",
       "         [0.66666669],\n",
       "         [0.96679997],\n",
       "         [0.32080001],\n",
       "         [0.85354996],\n",
       "         [0.14645001],\n",
       "         [0.27945206],\n",
       "         [0.77083337]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95071572],\n",
       "         [0.66666669],\n",
       "         [0.95675004],\n",
       "         [0.29664999],\n",
       "         [0.93299997],\n",
       "         [0.25      ],\n",
       "         [0.25479454],\n",
       "         [0.82499999]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.00754136],\n",
       "         [0.66666669],\n",
       "         [0.96985   ],\n",
       "         [0.329     ],\n",
       "         [0.98294997],\n",
       "         [0.37059999],\n",
       "         [0.23013699],\n",
       "         [0.80833334]]],\n",
       "\n",
       "\n",
       "       [[[1.        ],\n",
       "         [0.95172477],\n",
       "         [0.66666669],\n",
       "         [0.37905002],\n",
       "         [0.01484999],\n",
       "         [0.98294997],\n",
       "         [0.62940001],\n",
       "         [0.33150685],\n",
       "         [0.57499999]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95156538],\n",
       "         [0.66666669],\n",
       "         [0.38749999],\n",
       "         [0.01280001],\n",
       "         [0.93299997],\n",
       "         [0.75      ],\n",
       "         [0.32602739],\n",
       "         [0.62083334]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.02121671],\n",
       "         [0.66666669],\n",
       "         [0.3538    ],\n",
       "         [0.02184999],\n",
       "         [0.85354996],\n",
       "         [0.85354996],\n",
       "         [0.32602739],\n",
       "         [0.66666669]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.33719999],\n",
       "         [0.02724999],\n",
       "         [0.75      ],\n",
       "         [0.93299997],\n",
       "         [0.32876712],\n",
       "         [0.69583333]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.39605001],\n",
       "         [0.01095   ],\n",
       "         [0.62940001],\n",
       "         [0.98294997],\n",
       "         [0.34246576],\n",
       "         [0.69166672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.6462    ],\n",
       "         [0.02184999],\n",
       "         [0.5       ],\n",
       "         [1.        ],\n",
       "         [0.37534246],\n",
       "         [0.71250004]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.04012321],\n",
       "         [0.66666669],\n",
       "         [0.63779998],\n",
       "         [0.01934999],\n",
       "         [0.37059999],\n",
       "         [0.98294997],\n",
       "         [0.33972603],\n",
       "         [0.67083341]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95047665],\n",
       "         [0.66666669],\n",
       "         [0.59539998],\n",
       "         [0.00920001],\n",
       "         [0.25      ],\n",
       "         [0.93299997],\n",
       "         [0.3068493 ],\n",
       "         [0.70416671]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95005184],\n",
       "         [0.66666669],\n",
       "         [0.60395002],\n",
       "         [0.01095   ],\n",
       "         [0.14645001],\n",
       "         [0.85354996],\n",
       "         [0.30958903],\n",
       "         [0.75416672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.63535941],\n",
       "         [0.66666669],\n",
       "         [0.65450001],\n",
       "         [0.02445   ],\n",
       "         [0.067     ],\n",
       "         [0.75      ],\n",
       "         [0.31506848],\n",
       "         [0.83750004]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.63530636],\n",
       "         [0.66666669],\n",
       "         [0.68729997],\n",
       "         [0.03639999],\n",
       "         [0.01705   ],\n",
       "         [0.62940001],\n",
       "         [0.30958903],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.40094003],\n",
       "         [0.66666669],\n",
       "         [0.67919999],\n",
       "         [0.0332    ],\n",
       "         [0.        ],\n",
       "         [0.5       ],\n",
       "         [0.30136985],\n",
       "         [0.85000002]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.68817556],\n",
       "         [0.66666669],\n",
       "         [0.68729997],\n",
       "         [0.03639999],\n",
       "         [0.01705   ],\n",
       "         [0.37059999],\n",
       "         [0.29315066],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95050323],\n",
       "         [0.66666669],\n",
       "         [0.70335001],\n",
       "         [0.04324999],\n",
       "         [0.067     ],\n",
       "         [0.25      ],\n",
       "         [0.28219178],\n",
       "         [0.86666667]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95066261],\n",
       "         [0.66666669],\n",
       "         [0.71130002],\n",
       "         [0.04685   ],\n",
       "         [0.14645001],\n",
       "         [0.14645001],\n",
       "         [0.27945206],\n",
       "         [0.81666672]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95084846],\n",
       "         [0.66666669],\n",
       "         [0.727     ],\n",
       "         [0.05450001],\n",
       "         [0.25      ],\n",
       "         [0.067     ],\n",
       "         [0.27945206],\n",
       "         [0.77916664]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95106089],\n",
       "         [0.66666669],\n",
       "         [0.7723    ],\n",
       "         [0.08065   ],\n",
       "         [0.37059999],\n",
       "         [0.01705   ],\n",
       "         [0.27123287],\n",
       "         [0.68750006]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95095468],\n",
       "         [0.66666669],\n",
       "         [0.88855004],\n",
       "         [0.18535   ],\n",
       "         [0.5       ],\n",
       "         [0.        ],\n",
       "         [0.25205481],\n",
       "         [0.65833336]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95005184],\n",
       "         [0.66666669],\n",
       "         [0.96025002],\n",
       "         [0.30465001],\n",
       "         [0.62940001],\n",
       "         [0.01705   ],\n",
       "         [0.29863015],\n",
       "         [0.66250002]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95100772],\n",
       "         [0.66666669],\n",
       "         [0.96679997],\n",
       "         [0.32080001],\n",
       "         [0.75      ],\n",
       "         [0.067     ],\n",
       "         [0.28493151],\n",
       "         [0.74583334]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.03664463],\n",
       "         [0.66666669],\n",
       "         [0.96679997],\n",
       "         [0.32080001],\n",
       "         [0.85354996],\n",
       "         [0.14645001],\n",
       "         [0.27945206],\n",
       "         [0.77083337]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.95071572],\n",
       "         [0.66666669],\n",
       "         [0.95675004],\n",
       "         [0.29664999],\n",
       "         [0.93299997],\n",
       "         [0.25      ],\n",
       "         [0.25479454],\n",
       "         [0.82499999]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.00754136],\n",
       "         [0.66666669],\n",
       "         [0.96985   ],\n",
       "         [0.329     ],\n",
       "         [0.98294997],\n",
       "         [0.37059999],\n",
       "         [0.23013699],\n",
       "         [0.80833334]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.        ],\n",
       "         [0.66666669],\n",
       "         [0.98065001],\n",
       "         [0.36220002],\n",
       "         [1.        ],\n",
       "         [0.5       ],\n",
       "         [0.21369863],\n",
       "         [0.78750002]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a11d39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076cc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356184, 88128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0274244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dims(X_train, exogenous_data_train):\n",
    "    if args.model_name == \"mlp\":\n",
    "        input_dim = X_train.shape[1] * X_train.shape[2]\n",
    "    else:\n",
    "        input_dim = X_train.shape[2]\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        if len(exogenous_data_train) == 1:\n",
    "            cid = next(iter(exogenous_data_train.keys()))\n",
    "            exogenous_dim = exogenous_data_train[cid].shape[1]\n",
    "        else:\n",
    "            exogenous_dim = exogenous_data_train[\"all\"].shape[1]\n",
    "    else:\n",
    "        exogenous_dim = 0\n",
    "    \n",
    "    return input_dim, exogenous_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e90c8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model: str,\n",
    "              input_dim: int,\n",
    "              out_dim: int,\n",
    "              lags: int = 10,\n",
    "              exogenous_dim: int = 0,\n",
    "              seed=0):\n",
    "    if model == \"mlp\":\n",
    "        model = MLP(input_dim=input_dim, layer_units=[256, 128, 64], num_outputs=out_dim)\n",
    "    elif model == \"rnn\":\n",
    "        model = RNN(input_dim=input_dim, rnn_hidden_size=128, num_rnn_layers=1, rnn_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"lstm\":\n",
    "        model = LSTM(input_dim=input_dim, lstm_hidden_size=128, num_lstm_layers=1, lstm_dropout=0.0,\n",
    "                     layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"gru\":\n",
    "        model = GRU(input_dim=input_dim, gru_hidden_size=128, num_gru_layers=1, gru_dropout=0.0,\n",
    "                    layer_units=[128], num_outputs=out_dim, matrix_rep=True, exogenous_dim=exogenous_dim)\n",
    "    elif model == \"cnn\":\n",
    "        model = CNN(num_features=input_dim, lags=lags, exogenous_dim=exogenous_dim, out_dim=out_dim)\n",
    "    elif model == \"da_encoder_decoder\":\n",
    "        model = DualAttentionAutoEncoder(input_dim=input_dim, architecture=\"lstm\", matrix_rep=True)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Specified model is not implemented. Plese define your own model or choose one from ['mlp', 'rnn', 'lstm', 'gru', 'cnn', 'da_encoder_decoder']\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "495af4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "args.model_name = \"lstm\"\n",
    "\n",
    "input_dim, exogenous_dim = get_input_dims(X_train, exogenous_data_train)\n",
    "\n",
    "print(input_dim, exogenous_dim)\n",
    "\n",
    "model = get_model(model=args.model_name,\n",
    "                  input_dim=input_dim,\n",
    "                  out_dim=y_train.shape[1],\n",
    "                  lags=args.num_lags,\n",
    "                  exogenous_dim=exogenous_dim,\n",
    "                  seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1933251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(9, 128, batch_first=True)\n",
       "  (MLP_layers): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4b5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, X_train, y_train, X_val, y_val, \n",
    "        exogenous_data_train=None, exogenous_data_val=None, \n",
    "        idxs=[], # the indices of our targets in X\n",
    "        log_per=1):\n",
    "    \n",
    "    # get exogenous data (if any)\n",
    "    if exogenous_data_train is not None and len(exogenous_data_train) > 1:\n",
    "        exogenous_data_train = exogenous_data_train[\"all\"]\n",
    "        exogenous_data_val = exogenous_data_val[\"all\"]\n",
    "    elif exogenous_data_train is not None and len(exogenous_data_train) == 1:\n",
    "        cid = next(iter(exogenous_data_train.keys()))\n",
    "        exogenous_data_train = exogenous_data_train[cid]\n",
    "        exogenous_data_val = exogenous_data_val[cid]\n",
    "    else:\n",
    "        exogenous_data_train = None\n",
    "        exogenous_data_val = None\n",
    "    num_features = len(X_train[0][0])\n",
    "    \n",
    "    # to torch loader\n",
    "    train_loader = to_torch_dataset(X_train, y_train,\n",
    "                                    num_lags=args.num_lags,\n",
    "                                    num_features=num_features,\n",
    "                                    exogenous_data=exogenous_data_train,\n",
    "                                    indices=idxs,\n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=False)\n",
    "    val_loader = to_torch_dataset(X_val, y_val, \n",
    "                                  num_lags=args.num_lags,\n",
    "                                  num_features=num_features,\n",
    "                                  exogenous_data=exogenous_data_val,\n",
    "                                  indices=idxs,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False)\n",
    "    \n",
    "    # train the model\n",
    "    model = train(model, \n",
    "                  train_loader, val_loader,\n",
    "                  epochs=args.epochs,\n",
    "                  optimizer=args.optimizer, lr=args.lr,\n",
    "                  criterion=args.criterion,\n",
    "                  early_stopping=args.early_stopping,\n",
    "                  patience=args.patience,\n",
    "                  plot_history=args.plot_history, \n",
    "                  device=device, log_per=log_per,\n",
    "                  use_carbontracker=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7edadc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2025-10-28 14:27:28,018 | train_utils.py:97 | Epoch 1 [Train]: loss 0.008364582818680508, mse: 0.006722738966345787, rmse: 0.0819923104098536, mae 0.055085692554712296, r2: 0.8785467743873596, nrmse: 0.3552243623330862, sse: 2394.531982421875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:27:28,024 | train_utils.py:99 | Epoch 1 [Test]: loss 5.098015479600075e-05, mse: 0.00651918537914753, rmse: 0.08074147248562866, mae 0.053430404514074326, r2: 0.8995557427406311, nrmse: 0.3029875352041743, sse: 574.5227661132812, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:27:28,024 | helpers.py:154 | Validation loss decreased (inf --> 0.000051). Caching model ...\n",
      "INFO logger 2025-10-28 14:28:11,043 | train_utils.py:97 | Epoch 2 [Train]: loss 0.0065008177529659724, mse: 0.006727078929543495, rmse: 0.0820187718119669, mae 0.053660813719034195, r2: 0.8784683346748352, nrmse: 0.3553390039945438, sse: 2396.077880859375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:28:11,044 | train_utils.py:99 | Epoch 2 [Test]: loss 5.106612005952199e-05, mse: 0.006530110724270344, rmse: 0.08080910050402952, mae 0.0521121621131897, r2: 0.8993873596191406, nrmse: 0.30324131366492346, sse: 575.485595703125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:28:11,045 | helpers.py:142 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2025-10-28 14:28:53,868 | train_utils.py:97 | Epoch 3 [Train]: loss 0.006444898433272201, mse: 0.006784162018448114, rmse: 0.08236602466094933, mae 0.053383443504571915, r2: 0.8774370551109314, nrmse: 0.35684344595052153, sse: 2416.409912109375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:28:53,870 | train_utils.py:99 | Epoch 3 [Test]: loss 5.171372439404466e-05, mse: 0.006613112986087799, rmse: 0.0813210488501458, mae 0.05202401056885719, r2: 0.8981085419654846, nrmse: 0.30516243254926423, sse: 582.8004150390625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:28:53,870 | helpers.py:142 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2025-10-28 14:29:37,504 | train_utils.py:97 | Epoch 4 [Train]: loss 0.006391633519033747, mse: 0.006820003967732191, rmse: 0.08258331531085557, mae 0.05335448309779167, r2: 0.8767895698547363, nrmse: 0.35778483828558383, sse: 2429.17626953125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:29:37,505 | train_utils.py:99 | Epoch 4 [Test]: loss 5.256176564910245e-05, mse: 0.006721698213368654, rmse: 0.08198596351430319, mae 0.052340202033519745, r2: 0.8964354991912842, nrmse: 0.30765756731721167, sse: 592.3698120117188, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:29:37,505 | helpers.py:142 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2025-10-28 14:30:20,842 | train_utils.py:97 | Epoch 5 [Train]: loss 0.006334798189510979, mse: 0.006695688236504793, rmse: 0.08182718519236008, mae 0.05285622179508209, r2: 0.879035472869873, nrmse: 0.35450897207519444, sse: 2384.89697265625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:30:20,843 | train_utils.py:99 | Epoch 5 [Test]: loss 5.191719463792779e-05, mse: 0.006639242172241211, rmse: 0.08148154497946888, mae 0.05190063267946243, r2: 0.8977059721946716, nrmse: 0.3057647045308914, sse: 585.1031494140625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:30:20,843 | helpers.py:142 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2025-10-28 14:31:03,267 | train_utils.py:97 | Epoch 6 [Train]: loss 0.006259194473653414, mse: 0.006528195459395647, rmse: 0.0807972490830947, mae 0.052439555525779724, r2: 0.8820613622665405, nrmse: 0.35004686586268735, sse: 2325.23876953125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:31:03,267 | train_utils.py:99 | Epoch 6 [Test]: loss 5.079808244169033e-05, mse: 0.006495953071862459, rmse: 0.08059747559236864, mae 0.05153590068221092, r2: 0.8999136686325073, nrmse: 0.3024471776602408, sse: 572.475341796875, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:31:03,268 | helpers.py:154 | Validation loss decreased (0.000051 --> 0.000051). Caching model ...\n",
      "INFO logger 2025-10-28 14:31:46,073 | train_utils.py:97 | Epoch 7 [Train]: loss 0.006176833660154648, mse: 0.006397245451807976, rmse: 0.07998278222097538, mae 0.05196113884449005, r2: 0.8844271302223206, nrmse: 0.34651826092044885, sse: 2278.596435546875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:31:46,074 | train_utils.py:99 | Epoch 7 [Test]: loss 4.990760509778065e-05, mse: 0.006381792016327381, rmse: 0.07988611904659897, mae 0.05114360526204109, r2: 0.9016726016998291, nrmse: 0.29977776676372203, sse: 562.41455078125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:31:46,074 | helpers.py:154 | Validation loss decreased (0.000051 --> 0.000050). Caching model ...\n",
      "INFO logger 2025-10-28 14:32:28,787 | train_utils.py:97 | Epoch 8 [Train]: loss 0.006102324304940344, mse: 0.0063166189938783646, rmse: 0.07947716020265423, mae 0.05161219835281372, r2: 0.8858836889266968, nrmse: 0.34432769868184515, sse: 2249.878662109375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:32:28,788 | train_utils.py:99 | Epoch 8 [Test]: loss 4.9668434084201255e-05, mse: 0.006350951734930277, rmse: 0.07969285874487297, mae 0.05109787732362747, r2: 0.9021477699279785, nrmse: 0.2990525451313918, sse: 559.6966552734375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:32:28,788 | helpers.py:154 | Validation loss decreased (0.000050 --> 0.000050). Caching model ...\n",
      "INFO logger 2025-10-28 14:33:12,860 | train_utils.py:97 | Epoch 9 [Train]: loss 0.0060002586626737376, mse: 0.006247586105018854, rmse: 0.07904167321747974, mae 0.05089721828699112, r2: 0.887130856513977, nrmse: 0.34244099021077395, sse: 2225.290283203125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:33:12,860 | train_utils.py:99 | Epoch 9 [Test]: loss 4.9246149208816976e-05, mse: 0.006296873092651367, rmse: 0.07935283922237041, mae 0.0506226010620594, r2: 0.9029809832572937, nrmse: 0.2977766001445984, sse: 554.9308471679688, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:33:12,861 | helpers.py:154 | Validation loss decreased (0.000050 --> 0.000049). Caching model ...\n",
      "INFO logger 2025-10-28 14:33:56,266 | train_utils.py:97 | Epoch 10 [Train]: loss 0.005899685209601876, mse: 0.00614961190149188, rmse: 0.07841946124204043, mae 0.05030038207769394, r2: 0.888900876045227, nrmse: 0.33974531239529826, sse: 2190.393310546875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:33:56,267 | train_utils.py:99 | Epoch 10 [Test]: loss 4.896795626660465e-05, mse: 0.006261250004172325, rmse: 0.07912806078865023, mae 0.05040046572685242, r2: 0.9035298824310303, nrmse: 0.29693310470782575, sse: 551.7914428710938, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:33:56,267 | helpers.py:154 | Validation loss decreased (0.000049 --> 0.000049). Caching model ...\n",
      "INFO logger 2025-10-28 14:34:39,744 | train_utils.py:97 | Epoch 11 [Train]: loss 0.005791143236009262, mse: 0.006043110508471727, rmse: 0.0777374459862924, mae 0.04999963194131851, r2: 0.8908249139785767, nrmse: 0.33679054220875876, sse: 2152.459228515625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:34:39,744 | train_utils.py:99 | Epoch 11 [Test]: loss 4.940124161250487e-05, mse: 0.006316612474620342, rmse: 0.079477119189238, mae 0.050880350172519684, r2: 0.9026768803596497, nrmse: 0.2982429686622542, sse: 556.67041015625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:34:39,744 | helpers.py:142 | EarlyStopping counter: 1 out of 50\n",
      "INFO logger 2025-10-28 14:35:22,915 | train_utils.py:97 | Epoch 12 [Train]: loss 0.005659403701267161, mse: 0.005996719468384981, rmse: 0.0774384882883504, mae 0.05006648600101471, r2: 0.8916630148887634, nrmse: 0.3354953346815508, sse: 2135.935546875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:35:22,916 | train_utils.py:99 | Epoch 12 [Test]: loss 5.033314110067931e-05, mse: 0.006435754243284464, rmse: 0.08022315278823479, mae 0.051847413182258606, r2: 0.9008411765098572, nrmse: 0.3010425074170096, sse: 567.170166015625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:35:22,916 | helpers.py:142 | EarlyStopping counter: 2 out of 50\n",
      "INFO logger 2025-10-28 14:36:06,330 | train_utils.py:97 | Epoch 13 [Train]: loss 0.00553025745011935, mse: 0.005940471310168505, rmse: 0.07707445303191263, mae 0.04991587623953819, r2: 0.8926792144775391, nrmse: 0.33391818444406546, sse: 2115.90087890625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:36:06,331 | train_utils.py:99 | Epoch 13 [Test]: loss 5.063336314523478e-05, mse: 0.006474069785326719, rmse: 0.0804616044168069, mae 0.0518268421292305, r2: 0.9002508521080017, nrmse: 0.3019373123912358, sse: 570.5468139648438, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:36:06,331 | helpers.py:142 | EarlyStopping counter: 3 out of 50\n",
      "INFO logger 2025-10-28 14:36:49,111 | train_utils.py:97 | Epoch 14 [Train]: loss 0.005410889375277541, mse: 0.005825753323733807, rmse: 0.07632662264068682, mae 0.04975472763180733, r2: 0.8947517275810242, nrmse: 0.33067827606084516, sse: 2075.0400390625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:36:49,112 | train_utils.py:99 | Epoch 14 [Test]: loss 5.121593371963385e-05, mse: 0.006548473611474037, rmse: 0.08092263967193629, mae 0.052735645323991776, r2: 0.8991044759750366, nrmse: 0.3036673766480989, sse: 577.1038818359375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:36:49,112 | helpers.py:142 | EarlyStopping counter: 4 out of 50\n",
      "INFO logger 2025-10-28 14:37:32,161 | train_utils.py:97 | Epoch 15 [Train]: loss 0.005333905449048243, mse: 0.0057521238923072815, rmse: 0.07584275767868202, mae 0.04965833202004433, r2: 0.8960819244384766, nrmse: 0.32858197432566655, sse: 2048.814453125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:37:32,163 | train_utils.py:99 | Epoch 15 [Test]: loss 5.205798974527441e-05, mse: 0.006655899342149496, rmse: 0.0815836953205081, mae 0.05357176437973976, r2: 0.8974493145942688, nrmse: 0.30614803021345494, sse: 586.5711059570312, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:37:32,164 | helpers.py:142 | EarlyStopping counter: 5 out of 50\n",
      "INFO logger 2025-10-28 14:38:16,815 | train_utils.py:97 | Epoch 16 [Train]: loss 0.005247659249984342, mse: 0.005787513218820095, rmse: 0.07607570715294137, mae 0.05028991028666496, r2: 0.895442545413971, nrmse: 0.3295912071187903, sse: 2061.419677734375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:38:16,816 | train_utils.py:99 | Epoch 16 [Test]: loss 5.28845861628015e-05, mse: 0.006761541124433279, rmse: 0.08222859067522244, mae 0.05433201044797897, r2: 0.8958216309547424, nrmse: 0.3085680412434036, sse: 595.881103515625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:38:16,816 | helpers.py:142 | EarlyStopping counter: 6 out of 50\n",
      "INFO logger 2025-10-28 14:39:01,002 | train_utils.py:97 | Epoch 17 [Train]: loss 0.005177576843460659, mse: 0.005701266694813967, rmse: 0.07550673277803753, mae 0.04965917393565178, r2: 0.8970006704330444, nrmse: 0.3271261764531244, sse: 2030.699951171875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:39:01,003 | train_utils.py:99 | Epoch 17 [Test]: loss 5.355838300683946e-05, mse: 0.006848069839179516, rmse: 0.08275306543675295, mae 0.0544271245598793, r2: 0.8944884538650513, nrmse: 0.3105361663020742, sse: 603.5067138671875, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:39:01,003 | helpers.py:142 | EarlyStopping counter: 7 out of 50\n",
      "INFO logger 2025-10-28 14:39:44,946 | train_utils.py:97 | Epoch 18 [Train]: loss 0.0050033992587139794, mse: 0.005801850464195013, rmse: 0.07616987898241019, mae 0.05035967379808426, r2: 0.8951835632324219, nrmse: 0.3299991981597255, sse: 2066.5263671875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:39:44,947 | train_utils.py:99 | Epoch 18 [Test]: loss 5.643729170304447e-05, mse: 0.0072161550633609295, rmse: 0.08494795502753982, mae 0.05551747605204582, r2: 0.8888171911239624, nrmse: 0.3187726297536936, sse: 635.9453125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:39:44,947 | helpers.py:142 | EarlyStopping counter: 8 out of 50\n",
      "INFO logger 2025-10-28 14:40:28,437 | train_utils.py:97 | Epoch 19 [Train]: loss 0.004864508432411531, mse: 0.0056396229192614555, rmse: 0.07509742285366026, mae 0.04991919919848442, r2: 0.8981143832206726, nrmse: 0.3253528777601528, sse: 2008.743408203125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:40:28,439 | train_utils.py:99 | Epoch 19 [Test]: loss 5.615652825007817e-05, mse: 0.007180117070674896, rmse: 0.08473557146013058, mae 0.05537444353103638, r2: 0.8893724083900452, nrmse: 0.3179756468448341, sse: 632.7693481445312, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:40:28,440 | helpers.py:142 | EarlyStopping counter: 9 out of 50\n",
      "INFO logger 2025-10-28 14:41:11,361 | train_utils.py:97 | Epoch 20 [Train]: loss 0.004756247872895649, mse: 0.005519413854926825, rmse: 0.07429275775556339, mae 0.04945213720202446, r2: 0.900286078453064, nrmse: 0.32186673808517174, sse: 1965.9268798828125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:41:11,362 | train_utils.py:99 | Epoch 20 [Test]: loss 5.626604206059108e-05, mse: 0.007194234989583492, rmse: 0.08481883628996269, mae 0.05544790253043175, r2: 0.8891549110412598, nrmse: 0.31828810343973346, sse: 634.0135498046875, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:41:11,362 | helpers.py:142 | EarlyStopping counter: 10 out of 50\n",
      "INFO logger 2025-10-28 14:41:58,801 | train_utils.py:97 | Epoch 21 [Train]: loss 0.0046318828421115284, mse: 0.005591321270912886, rmse: 0.07477513805345254, mae 0.05009525269269943, r2: 0.8989869952201843, nrmse: 0.3239566076456607, sse: 1991.5391845703125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:41:58,802 | train_utils.py:99 | Epoch 21 [Test]: loss 5.915298549091289e-05, mse: 0.007563391700387001, rmse: 0.08696776242026123, mae 0.05703532695770264, r2: 0.8834671378135681, nrmse: 0.32635208606862215, sse: 666.5465698242188, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:41:58,802 | helpers.py:142 | EarlyStopping counter: 11 out of 50\n",
      "INFO logger 2025-10-28 14:42:42,895 | train_utils.py:97 | Epoch 22 [Train]: loss 0.0045664297952806125, mse: 0.005659443326294422, rmse: 0.0752292717384292, mae 0.050537873059511185, r2: 0.8977562785148621, nrmse: 0.32592410127833704, sse: 2015.80322265625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:42:42,896 | train_utils.py:99 | Epoch 22 [Test]: loss 6.040777908887309e-05, mse: 0.007723892107605934, rmse: 0.08788567635062004, mae 0.05790000036358833, r2: 0.8809942007064819, nrmse: 0.3297966167506517, sse: 680.691162109375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:42:42,896 | helpers.py:142 | EarlyStopping counter: 12 out of 50\n",
      "INFO logger 2025-10-28 14:43:26,293 | train_utils.py:97 | Epoch 23 [Train]: loss 0.004472082600602311, mse: 0.00558466324582696, rmse: 0.07473060447920223, mae 0.050326719880104065, r2: 0.8991072773933411, nrmse: 0.32376366991239763, sse: 1989.167724609375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:43:26,294 | train_utils.py:99 | Epoch 23 [Test]: loss 5.981672707149963e-05, mse: 0.007648169994354248, rmse: 0.08745381635099893, mae 0.057465922087430954, r2: 0.8821609020233154, nrmse: 0.32817603450449845, sse: 674.0179443359375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:43:26,294 | helpers.py:142 | EarlyStopping counter: 13 out of 50\n",
      "INFO logger 2025-10-28 14:44:09,681 | train_utils.py:97 | Epoch 24 [Train]: loss 0.004381766629758707, mse: 0.005582693964242935, rmse: 0.07471742744663346, mae 0.05037815496325493, r2: 0.899142861366272, nrmse: 0.32370658159559956, sse: 1988.4661865234375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:44:09,682 | train_utils.py:99 | Epoch 24 [Test]: loss 6.122063274357542e-05, mse: 0.007828124798834324, rmse: 0.08847669070910329, mae 0.0581379272043705, r2: 0.8793882727622986, nrmse: 0.3320144358990328, sse: 689.876953125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:44:09,682 | helpers.py:142 | EarlyStopping counter: 14 out of 50\n",
      "INFO logger 2025-10-28 14:44:56,411 | train_utils.py:97 | Epoch 25 [Train]: loss 0.004309374033268879, mse: 0.005533434450626373, rmse: 0.07438705835443672, mae 0.05020733177661896, r2: 0.9000327587127686, nrmse: 0.32227528700805197, sse: 1970.9207763671875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:44:56,412 | train_utils.py:99 | Epoch 25 [Test]: loss 6.140064860850472e-05, mse: 0.007850728929042816, rmse: 0.08860433922242644, mae 0.05834399536252022, r2: 0.879040002822876, nrmse: 0.33249344510252665, sse: 691.8690795898438, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:44:56,412 | helpers.py:142 | EarlyStopping counter: 15 out of 50\n",
      "INFO logger 2025-10-28 14:45:45,814 | train_utils.py:97 | Epoch 26 [Train]: loss 0.004233420788459972, mse: 0.0053906915709376335, rmse: 0.07342132912810577, mae 0.04920416325330734, r2: 0.9026115536689758, nrmse: 0.31809135138171046, sse: 1920.078125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:45:45,815 | train_utils.py:99 | Epoch 26 [Test]: loss 6.092475637038342e-05, mse: 0.0077895368449389935, rmse: 0.08825835283381961, mae 0.05775986239314079, r2: 0.8799827694892883, nrmse: 0.3311951090693705, sse: 686.476318359375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:45:45,815 | helpers.py:142 | EarlyStopping counter: 16 out of 50\n",
      "INFO logger 2025-10-28 14:46:29,523 | train_utils.py:97 | Epoch 27 [Train]: loss 0.004139788824253128, mse: 0.005267363041639328, rmse: 0.07257660119927997, mae 0.048809271305799484, r2: 0.9048396348953247, nrmse: 0.3144316430705024, sse: 1876.150390625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:46:29,524 | train_utils.py:99 | Epoch 27 [Test]: loss 6.145358903157759e-05, mse: 0.007857552729547024, rmse: 0.0886428380048102, mae 0.05820804089307785, r2: 0.8789348602294922, nrmse: 0.3326379142436473, sse: 692.4703979492188, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:46:29,524 | helpers.py:142 | EarlyStopping counter: 17 out of 50\n",
      "INFO logger 2025-10-28 14:47:13,528 | train_utils.py:97 | Epoch 28 [Train]: loss 0.004083839017329614, mse: 0.005246583838015795, rmse: 0.07243330613754832, mae 0.04852764680981636, r2: 0.9052150249481201, nrmse: 0.31381083001285515, sse: 1868.7491455078125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:47:13,529 | train_utils.py:99 | Epoch 28 [Test]: loss 6.0501061706878474e-05, mse: 0.007735721301287413, rmse: 0.08795294936093623, mae 0.05743102356791496, r2: 0.8808119297027588, nrmse: 0.3300490630208766, sse: 681.733642578125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:47:13,529 | helpers.py:142 | EarlyStopping counter: 18 out of 50\n",
      "INFO logger 2025-10-28 14:47:59,580 | train_utils.py:97 | Epoch 29 [Train]: loss 0.003987740918108725, mse: 0.005347782280296087, rmse: 0.0731285326004569, mae 0.049327339977025986, r2: 0.9033867716789246, nrmse: 0.3168228365745596, sse: 1904.79443359375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:47:59,583 | train_utils.py:99 | Epoch 29 [Test]: loss 6.318378094763826e-05, mse: 0.008078787475824356, rmse: 0.08988207538672188, mae 0.05900782719254494, r2: 0.8755261898040771, nrmse: 0.33728823171147804, sse: 711.9674072265625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:47:59,583 | helpers.py:142 | EarlyStopping counter: 19 out of 50\n",
      "INFO logger 2025-10-28 14:48:44,380 | train_utils.py:97 | Epoch 30 [Train]: loss 0.003935953731629967, mse: 0.005242606624960899, rmse: 0.07240584662139446, mae 0.04833872616291046, r2: 0.9052869081497192, nrmse: 0.3136918641114557, sse: 1867.33251953125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:48:44,381 | train_utils.py:99 | Epoch 30 [Test]: loss 6.233936456858736e-05, mse: 0.007970687933266163, rmse: 0.08927870929435619, mae 0.05833522230386734, r2: 0.8771917223930359, nrmse: 0.33502406189237804, sse: 702.4407958984375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:48:44,381 | helpers.py:142 | EarlyStopping counter: 20 out of 50\n",
      "INFO logger 2025-10-28 14:49:32,615 | train_utils.py:97 | Epoch 31 [Train]: loss 0.003874338018465563, mse: 0.005157084669917822, rmse: 0.07181284474185536, mae 0.04824821650981903, r2: 0.9068319201469421, nrmse: 0.3111227364277908, sse: 1836.8709716796875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:49:32,616 | train_utils.py:99 | Epoch 31 [Test]: loss 6.287374901463117e-05, mse: 0.008038647472858429, rmse: 0.0896585047436016, mae 0.05869636684656143, r2: 0.8761446475982666, nrmse: 0.3364492685861141, sse: 708.429931640625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:49:32,616 | helpers.py:142 | EarlyStopping counter: 21 out of 50\n",
      "INFO logger 2025-10-28 14:50:18,360 | train_utils.py:97 | Epoch 32 [Train]: loss 0.003829485888518356, mse: 0.005181108135730028, rmse: 0.07197991480774361, mae 0.04820607602596283, r2: 0.9063978791236877, nrmse: 0.3118465525676635, sse: 1845.4278564453125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:50:18,361 | train_utils.py:99 | Epoch 32 [Test]: loss 6.256015774108419e-05, mse: 0.007998454384505749, rmse: 0.0894340784293423, mae 0.05822814255952835, r2: 0.8767639398574829, nrmse: 0.3356070945001203, sse: 704.8877563476562, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:50:18,361 | helpers.py:142 | EarlyStopping counter: 22 out of 50\n",
      "INFO logger 2025-10-28 14:51:10,195 | train_utils.py:97 | Epoch 33 [Train]: loss 0.0037697185867640384, mse: 0.005168418399989605, rmse: 0.07189171301332029, mae 0.04815684258937836, r2: 0.9066271781921387, nrmse: 0.3114644261703947, sse: 1840.907958984375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:51:10,198 | train_utils.py:99 | Epoch 33 [Test]: loss 6.324171641765896e-05, mse: 0.008085804060101509, rmse: 0.08992109908192576, mae 0.05866675451397896, r2: 0.8754180669784546, nrmse: 0.33743467062150023, sse: 712.5857543945312, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:51:10,198 | helpers.py:142 | EarlyStopping counter: 23 out of 50\n",
      "INFO logger 2025-10-28 14:52:00,432 | train_utils.py:97 | Epoch 34 [Train]: loss 0.0037214578266409996, mse: 0.005086326971650124, rmse: 0.07131848968991228, mae 0.047699231654405594, r2: 0.9081102609634399, nrmse: 0.308980987314797, sse: 1811.668212890625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:52:00,434 | train_utils.py:99 | Epoch 34 [Test]: loss 6.389403024124051e-05, mse: 0.008169861510396004, rmse: 0.09038728622099462, mae 0.058942265808582306, r2: 0.8741229772567749, nrmse: 0.3391840676520721, sse: 719.9935302734375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:52:00,434 | helpers.py:142 | EarlyStopping counter: 24 out of 50\n",
      "INFO logger 2025-10-28 14:52:44,822 | train_utils.py:97 | Epoch 35 [Train]: loss 0.003667259833997917, mse: 0.00498479139059782, rmse: 0.07060305510810294, mae 0.04712042212486267, r2: 0.9099445939064026, nrmse: 0.30588143088268893, sse: 1775.5029296875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:52:44,822 | train_utils.py:99 | Epoch 35 [Test]: loss 6.357335952467221e-05, mse: 0.008128139190375805, rmse: 0.09015619330015995, mae 0.05861697718501091, r2: 0.8747657537460327, nrmse: 0.33831687669888144, sse: 716.316650390625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:52:44,823 | helpers.py:142 | EarlyStopping counter: 25 out of 50\n",
      "INFO logger 2025-10-28 14:53:30,660 | train_utils.py:97 | Epoch 36 [Train]: loss 0.0036126557498358117, mse: 0.005023843143135309, rmse: 0.0708790740849181, mae 0.04733927547931671, r2: 0.9092390537261963, nrmse: 0.30707725844921174, sse: 1789.4124755859375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:53:30,661 | train_utils.py:99 | Epoch 36 [Test]: loss 6.38332399522239e-05, mse: 0.008161770179867744, rmse: 0.090342515904018, mae 0.058837831020355225, r2: 0.8742476105690002, nrmse: 0.3390160641766157, sse: 719.2804565429688, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:53:30,661 | helpers.py:142 | EarlyStopping counter: 26 out of 50\n",
      "INFO logger 2025-10-28 14:54:17,935 | train_utils.py:97 | Epoch 37 [Train]: loss 0.0035769593865288395, mse: 0.004991776775568724, rmse: 0.07065250721360654, mae 0.047095440328121185, r2: 0.9098183512687683, nrmse: 0.3060956777133458, sse: 1777.9910888671875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:54:17,936 | train_utils.py:99 | Epoch 37 [Test]: loss 6.474613979192267e-05, mse: 0.008278249762952328, rmse: 0.09098488755256187, mae 0.059341445565223694, r2: 0.872452974319458, nrmse: 0.3414266048378848, sse: 729.5455932617188, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:54:17,936 | helpers.py:142 | EarlyStopping counter: 27 out of 50\n",
      "INFO logger 2025-10-28 14:55:03,585 | train_utils.py:97 | Epoch 38 [Train]: loss 0.003533119111860397, mse: 0.005034215748310089, rmse: 0.07095220749427102, mae 0.04752424359321594, r2: 0.9090516567230225, nrmse: 0.30739410241388077, sse: 1793.1070556640625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:55:03,586 | train_utils.py:99 | Epoch 38 [Test]: loss 6.540293259851391e-05, mse: 0.008362754248082638, rmse: 0.0914480959237678, mae 0.059787195175886154, r2: 0.8711509704589844, nrmse: 0.3431648238516959, sse: 736.9927978515625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:55:03,587 | helpers.py:142 | EarlyStopping counter: 28 out of 50\n",
      "INFO logger 2025-10-28 14:55:49,442 | train_utils.py:97 | Epoch 39 [Train]: loss 0.0034848243845135617, mse: 0.004899878520518541, rmse: 0.06999913228404007, mae 0.04672142490744591, r2: 0.9114786386489868, nrmse: 0.3032649891821957, sse: 1745.25830078125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:55:49,443 | train_utils.py:99 | Epoch 39 [Test]: loss 6.483347749681918e-05, mse: 0.008289705961942673, rmse: 0.09104782238989943, mae 0.05944642424583435, r2: 0.8722764253616333, nrmse: 0.3416627718367809, sse: 730.5552368164062, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:55:49,443 | helpers.py:142 | EarlyStopping counter: 29 out of 50\n",
      "INFO logger 2025-10-28 14:56:35,402 | train_utils.py:97 | Epoch 40 [Train]: loss 0.0034508214326432504, mse: 0.005026089958846569, rmse: 0.07089492195387882, mae 0.047352444380521774, r2: 0.9091984629631042, nrmse: 0.30714591792615253, sse: 1790.212890625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:56:35,403 | train_utils.py:99 | Epoch 40 [Test]: loss 6.6129527853344e-05, mse: 0.008455499075353146, rmse: 0.09195378771618462, mae 0.060239627957344055, r2: 0.8697220087051392, nrmse: 0.34506246461846074, sse: 745.166259765625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:56:35,403 | helpers.py:142 | EarlyStopping counter: 30 out of 50\n",
      "INFO logger 2025-10-28 14:57:25,736 | train_utils.py:97 | Epoch 41 [Train]: loss 0.0033864808171107244, mse: 0.004839449189603329, rmse: 0.0695661497396782, mae 0.046498026698827744, r2: 0.9125703573226929, nrmse: 0.30138913097728015, sse: 1723.734375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:57:25,736 | train_utils.py:99 | Epoch 41 [Test]: loss 6.499645331174613e-05, mse: 0.008310568518936634, rmse: 0.0911623196224001, mae 0.05929417535662651, r2: 0.8719550371170044, nrmse: 0.3420924300185691, sse: 732.393798828125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:57:25,737 | helpers.py:142 | EarlyStopping counter: 31 out of 50\n",
      "INFO logger 2025-10-28 14:58:11,357 | train_utils.py:97 | Epoch 42 [Train]: loss 0.003377437551416011, mse: 0.00482253497466445, rmse: 0.06944447403979995, mae 0.046362247318029404, r2: 0.9128758907318115, nrmse: 0.3008619818740944, sse: 1717.7098388671875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:58:11,358 | train_utils.py:99 | Epoch 42 [Test]: loss 6.537520129529615e-05, mse: 0.008359602652490139, rmse: 0.09143086269138086, mae 0.05958013981580734, r2: 0.8711994886398315, nrmse: 0.34310015504589164, sse: 736.715087890625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:58:11,359 | helpers.py:142 | EarlyStopping counter: 32 out of 50\n",
      "INFO logger 2025-10-28 14:58:57,031 | train_utils.py:97 | Epoch 43 [Train]: loss 0.0033330688860701272, mse: 0.0048279366455972195, rmse: 0.06948335516940168, mae 0.046385228633880615, r2: 0.9127783179283142, nrmse: 0.3010304308957225, sse: 1719.6337890625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:58:57,032 | train_utils.py:99 | Epoch 43 [Test]: loss 6.609468334450839e-05, mse: 0.008450973778963089, rmse: 0.09192917806095674, mae 0.05997256934642792, r2: 0.8697917461395264, nrmse: 0.34497011531456306, sse: 744.7673950195312, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:58:57,032 | helpers.py:142 | EarlyStopping counter: 33 out of 50\n",
      "INFO logger 2025-10-28 14:59:43,376 | train_utils.py:97 | Epoch 44 [Train]: loss 0.003288154150071118, mse: 0.004766523372381926, rmse: 0.06904001283590498, mae 0.04624124616384506, r2: 0.9138877987861633, nrmse: 0.29910968982958586, sse: 1697.7593994140625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 14:59:43,376 | train_utils.py:99 | Epoch 44 [Test]: loss 6.479205064524233e-05, mse: 0.008284525014460087, rmse: 0.09101936615061702, mae 0.059339623898267746, r2: 0.8723562955856323, nrmse: 0.34155598798040654, sse: 730.0986328125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 14:59:43,377 | helpers.py:142 | EarlyStopping counter: 34 out of 50\n",
      "INFO logger 2025-10-28 15:00:28,894 | train_utils.py:97 | Epoch 45 [Train]: loss 0.0032555320376147622, mse: 0.004838695749640465, rmse: 0.06956073425173476, mae 0.04671918600797653, r2: 0.9125839471817017, nrmse: 0.3013656688594082, sse: 1723.466064453125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:00:28,894 | train_utils.py:99 | Epoch 45 [Test]: loss 6.719581803518917e-05, mse: 0.008592434227466583, rmse: 0.09269538406774408, mae 0.06073299050331116, r2: 0.8676121830940247, nrmse: 0.3478453523186498, sse: 757.2340087890625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:00:28,895 | helpers.py:142 | EarlyStopping counter: 35 out of 50\n",
      "INFO logger 2025-10-28 15:01:15,056 | train_utils.py:97 | Epoch 46 [Train]: loss 0.003236314537920318, mse: 0.00483695836737752, rmse: 0.06954824489070532, mae 0.04667224362492561, r2: 0.9126152992248535, nrmse: 0.3013115598181402, sse: 1722.84716796875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:01:15,057 | train_utils.py:99 | Epoch 46 [Test]: loss 6.619322890518803e-05, mse: 0.008464209735393524, rmse: 0.09200113985920785, mae 0.060106564313173294, r2: 0.869587779045105, nrmse: 0.3452401565611461, sse: 745.933837890625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:01:15,057 | helpers.py:142 | EarlyStopping counter: 36 out of 50\n",
      "INFO logger 2025-10-28 15:02:00,061 | train_utils.py:97 | Epoch 47 [Train]: loss 0.003187908875273907, mse: 0.004830724094063044, rmse: 0.06950341066496696, mae 0.04652169346809387, r2: 0.912727952003479, nrmse: 0.3011173195391555, sse: 1720.6265869140625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:02:00,062 | train_utils.py:99 | Epoch 47 [Test]: loss 6.652477517314195e-05, mse: 0.008506759069859982, rmse: 0.09223209349169074, mae 0.0602341927587986, r2: 0.8689321875572205, nrmse: 0.3461068248258956, sse: 749.6836547851562, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:02:00,063 | helpers.py:142 | EarlyStopping counter: 37 out of 50\n",
      "INFO logger 2025-10-28 15:02:45,860 | train_utils.py:97 | Epoch 48 [Train]: loss 0.003162250475055865, mse: 0.004853833932429552, rmse: 0.06966946197890114, mae 0.04659353196620941, r2: 0.9123104810714722, nrmse: 0.3018367220271692, sse: 1728.8580322265625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:02:45,861 | train_utils.py:99 | Epoch 48 [Test]: loss 6.710553502020663e-05, mse: 0.008580684661865234, rmse: 0.09263198509081641, mae 0.06057092174887657, r2: 0.8677932024002075, nrmse: 0.34760744360628143, sse: 756.1986083984375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:02:45,861 | helpers.py:142 | EarlyStopping counter: 38 out of 50\n",
      "INFO logger 2025-10-28 15:03:29,168 | train_utils.py:97 | Epoch 49 [Train]: loss 0.0031552541171670084, mse: 0.0047013661824166775, rmse: 0.06856650918937522, mae 0.04571659862995148, r2: 0.9150649309158325, nrmse: 0.297058277568361, sse: 1674.5513916015625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:03:29,169 | train_utils.py:99 | Epoch 49 [Test]: loss 6.628967114807726e-05, mse: 0.008476806804537773, rmse: 0.09206957588985502, mae 0.06011238321661949, r2: 0.8693937063217163, nrmse: 0.34549696713948463, sse: 747.0440673828125, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:03:29,169 | helpers.py:142 | EarlyStopping counter: 39 out of 50\n",
      "INFO logger 2025-10-28 15:04:13,289 | train_utils.py:97 | Epoch 50 [Train]: loss 0.003109538880823715, mse: 0.004876216407865286, rmse: 0.06982991055318119, mae 0.04690099135041237, r2: 0.9119060635566711, nrmse: 0.3025318511459973, sse: 1736.830322265625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:04:13,290 | train_utils.py:99 | Epoch 50 [Test]: loss 6.864464855637484e-05, mse: 0.008777826093137264, rmse: 0.09369005333084865, mae 0.061601269990205765, r2: 0.8647557497024536, nrmse: 0.3515779122917794, sse: 773.572265625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:04:13,290 | helpers.py:142 | EarlyStopping counter: 40 out of 50\n",
      "INFO logger 2025-10-28 15:05:06,551 | train_utils.py:97 | Epoch 51 [Train]: loss 0.003096818819707658, mse: 0.004704534541815519, rmse: 0.0685896095761998, mae 0.046145159751176834, r2: 0.9150077104568481, nrmse: 0.29715835793124373, sse: 1675.679931640625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:05:06,553 | train_utils.py:99 | Epoch 51 [Test]: loss 6.811974988313992e-05, mse: 0.00871075689792633, rmse: 0.09333143574341032, mae 0.06114426627755165, r2: 0.8657891154289246, nrmse: 0.35023217687782415, sse: 767.66162109375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:05:06,553 | helpers.py:142 | EarlyStopping counter: 41 out of 50\n",
      "INFO logger 2025-10-28 15:05:57,068 | train_utils.py:97 | Epoch 52 [Train]: loss 0.003068138528709774, mse: 0.004609751049429178, rmse: 0.06789514746599479, mae 0.04551839083433151, r2: 0.9167200326919556, nrmse: 0.29414966285936517, sse: 1641.9195556640625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:05:57,070 | train_utils.py:99 | Epoch 52 [Test]: loss 6.681865561298587e-05, mse: 0.008544672280550003, rmse: 0.09243739654787993, mae 0.06035825237631798, r2: 0.8683480620384216, nrmse: 0.346877237663929, sse: 753.02490234375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:05:57,070 | helpers.py:142 | EarlyStopping counter: 42 out of 50\n",
      "INFO logger 2025-10-28 15:06:42,755 | train_utils.py:97 | Epoch 53 [Train]: loss 0.0030339427541951776, mse: 0.004677447956055403, rmse: 0.06839187054069659, mae 0.04581393301486969, r2: 0.9154970645904541, nrmse: 0.29630167121947926, sse: 1666.0321044921875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:06:42,756 | train_utils.py:99 | Epoch 53 [Test]: loss 6.757484908261799e-05, mse: 0.008640782907605171, rmse: 0.09295581158596364, mae 0.06082818657159805, r2: 0.8668672442436218, nrmse: 0.34882262322312496, sse: 761.4949340820312, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:06:42,756 | helpers.py:142 | EarlyStopping counter: 43 out of 50\n",
      "INFO logger 2025-10-28 15:07:26,056 | train_utils.py:97 | Epoch 54 [Train]: loss 0.002973018105680935, mse: 0.004686242435127497, rmse: 0.06845613511678479, mae 0.045942679047584534, r2: 0.9153381586074829, nrmse: 0.29658009175608113, sse: 1669.16455078125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:07:26,057 | train_utils.py:99 | Epoch 54 [Test]: loss 6.841359296005643e-05, mse: 0.008748150430619717, rmse: 0.09353154778265843, mae 0.06123581901192665, r2: 0.8652129769325256, nrmse: 0.3509831100930595, sse: 770.9569702148438, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:07:26,057 | helpers.py:142 | EarlyStopping counter: 44 out of 50\n",
      "INFO logger 2025-10-28 15:08:10,758 | train_utils.py:97 | Epoch 55 [Train]: loss 0.0029801871184726653, mse: 0.004716214723885059, rmse: 0.06867470221184115, mae 0.0461607351899147, r2: 0.9147967100143433, nrmse: 0.29752701417576033, sse: 1679.8402099609375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:08:10,759 | train_utils.py:99 | Epoch 55 [Test]: loss 7.006554023584188e-05, mse: 0.008959578350186348, rmse: 0.09465504925880261, mae 0.06228068843483925, r2: 0.8619554042816162, nrmse: 0.35519912117851205, sse: 789.5897216796875, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:08:10,759 | helpers.py:142 | EarlyStopping counter: 45 out of 50\n",
      "INFO logger 2025-10-28 15:08:55,229 | train_utils.py:97 | Epoch 56 [Train]: loss 0.0029288933874497595, mse: 0.0047257402911782265, rmse: 0.0687440200394058, mae 0.04613695666193962, r2: 0.9146245718002319, nrmse: 0.2978273274730913, sse: 1683.2330322265625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:08:55,230 | train_utils.py:99 | Epoch 56 [Test]: loss 7.027763203111777e-05, mse: 0.00898628868162632, rmse: 0.09479603726752675, mae 0.06227286905050278, r2: 0.8615438342094421, nrmse: 0.355728187690945, sse: 791.9436645507812, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:08:55,230 | helpers.py:142 | EarlyStopping counter: 46 out of 50\n",
      "INFO logger 2025-10-28 15:09:39,011 | train_utils.py:97 | Epoch 57 [Train]: loss 0.0029412048090759805, mse: 0.00468991044908762, rmse: 0.06848292085686489, mae 0.04571295902132988, r2: 0.9152718782424927, nrmse: 0.29669613858281413, sse: 1670.4710693359375, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:09:39,012 | train_utils.py:99 | Epoch 57 [Test]: loss 6.857702107092572e-05, mse: 0.008769065141677856, rmse: 0.09364328668771647, mae 0.06114841252565384, r2: 0.8648906946182251, nrmse: 0.35140241747485107, sse: 772.8001708984375, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:09:39,012 | helpers.py:142 | EarlyStopping counter: 47 out of 50\n",
      "INFO logger 2025-10-28 15:10:24,061 | train_utils.py:97 | Epoch 58 [Train]: loss 0.0028907478113172316, mse: 0.0046994308941066265, rmse: 0.06855239524704171, mae 0.045830290764570236, r2: 0.9150999188423157, nrmse: 0.2969971301736801, sse: 1673.862060546875, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:10:24,062 | train_utils.py:99 | Epoch 58 [Test]: loss 6.903644026822614e-05, mse: 0.00882776454091072, rmse: 0.09395618415469373, mae 0.06153322383761406, r2: 0.8639863133430481, nrmse: 0.3525765852150783, sse: 777.9732666015625, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:10:24,062 | helpers.py:142 | EarlyStopping counter: 48 out of 50\n",
      "INFO logger 2025-10-28 15:11:09,393 | train_utils.py:97 | Epoch 59 [Train]: loss 0.0028789333553323497, mse: 0.004617616534233093, rmse: 0.06795304654121913, mae 0.04540836438536644, r2: 0.916577935218811, nrmse: 0.29440050543196045, sse: 1644.72119140625, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:11:09,394 | train_utils.py:99 | Epoch 59 [Test]: loss 6.955385532943003e-05, mse: 0.008894219063222408, rmse: 0.09430916743998119, mae 0.06199858337640762, r2: 0.8629624247550964, nrmse: 0.3539011775501581, sse: 783.8297729492188, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:11:09,394 | helpers.py:142 | EarlyStopping counter: 49 out of 50\n",
      "INFO logger 2025-10-28 15:11:54,150 | train_utils.py:97 | Epoch 60 [Train]: loss 0.002849771795383421, mse: 0.004620185121893883, rmse: 0.0679719436377531, mae 0.04558032378554344, r2: 0.9165315628051758, nrmse: 0.29448237541504385, sse: 1645.635986328125, sst: 19715.66796875\n",
      "INFO logger 2025-10-28 15:11:54,151 | train_utils.py:99 | Epoch 60 [Test]: loss 7.006224378583534e-05, mse: 0.008959655649960041, rmse: 0.0946554575814836, mae 0.06226018816232681, r2: 0.8619542121887207, nrmse: 0.3552006534354659, sse: 789.5965576171875, sst: 5719.81591796875\n",
      "INFO logger 2025-10-28 15:11:54,152 | helpers.py:142 | EarlyStopping counter: 50 out of 50\n",
      "INFO logger 2025-10-28 15:11:54,152 | train_utils.py:117 | Early Stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2025-10-28 15:11:54,325 | train_utils.py:140 | Best Loss: 4.896795626660465e-05, Best epoch: 60\n"
     ]
    }
   ],
   "source": [
    "trained_model = fit(model, X_train, y_train, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
